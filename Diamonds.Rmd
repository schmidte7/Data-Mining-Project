---
title: "Diamonds"
author: "Francisco Arrieta, Emily Schmidt and Lucia Camenisch"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true             # creating a table of contents (toc)
    toc_float: 
      collapsed: false    # toc does not collapse and is shown as a sidebar (toc_float)
    number_sections: true # document sections are numbered
    theme: cosmo
---

```{=html}
<style>
body{
  color: #2F91AE;
  background-color: #F2F2F2;
}
pre{
  background-color: #96EAE3;
}
pre:not([class]){
  background-color: #15DDD8;
}
.toc-content{
  padding-left: 10px;
  padding-right: 10px;
}
.col-sm-8 {
  width: 75%;
}
code {
  color: #333333;
  background-color: #96EAE3;
}
</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.align = "center")
```

```{r Colors, include=FALSE}
#Aqua =         "#15DDD8"
#Dark Blue =    "#2F91AE"
#Yellow =       "#F9D53E"
#Light Gray =   "#F2F2F2"
#Light Aqua =   "#96EAE3"

#library("colorspace")
#pal <- choose_palette()
#display.brewer.all()

```

```{r Libraries}
library(data.table)     #for reading data.tables
library(kableExtra)     #for more elaborate tables
library(ggplot2)        #for making graphs
library(GGally)         #for making graphs
library(dplyr)          #for data manipulation
library(tidyr)          #for changing the shape and hierarchy of a data set
library(DataExplorer)   #for graphing missing value percentages
library(car)            #for statistic functions
library(rpart)          # trees
library(rpart.plot)     # plot trees
library(forecast)       # accuracy
library(ggplot2)        # visualizations
library(rattle) # Graphical Data Interface
library(RColorBrewer) # Contains a ready-to-use color palettes for creating beautiful graphics
library(Metrics) # RMSE()
library(forecast)       # accuracy
library(caret)
library(randomForest)
library(adabag)

#source("VIF.R")
```

# Data Exploration 

```{r Import Data}
diamonds <- fread("diamonds.csv", sep=",", header = T) # Load your data, diamonds.csv

diamonds$V1 <- NULL # Remove column 'V1' as it is similar to an ID variable - no additional meaning derived

# Rename columns for more precise names
colnames(diamonds)[5] <- "depth_ratio" # depth to depth_ratio
colnames(diamonds)[8] <- "length" # x to length
colnames(diamonds)[9] <- "width"  # y to width
colnames(diamonds)[10] <- "depth" # z to depth

# add variable to confirm the depth ratio  
#explain the 2 times x in the depth formula

dim(diamonds) # Dimensions of data
summary(diamonds) # Produce result summaries of all variables
str(diamonds) # Type of variables

# Number of unique values in each variable
sapply(diamonds, function(x) length(unique(x)))

# Missing values analysis
plot_missing(diamonds) # Plots the percentages of missing values

# pairs(diamonds[, c(1, 5:10)])
```


```{r Variables check}
# carat no problems


unique(diamonds$cut) # Review unique values for cut
diamonds$cut <- as.factor(diamonds$cut) # Factor the cut to five levels 
diamonds$cut <- ordered(diamonds$cut, levels = c("Fair", "Good", "Very Good", "Premium", "Ideal")) # Ordered from worst to best

unique(diamonds$color) # Review unique values for color
diamonds$color <- as.factor(diamonds$color) # Factor the color to seven levels 
diamonds$color <- ordered(diamonds$color, levels = c("J", "I", "H", "G", "F", "E", "D")) # Ordered from worst to best

unique(diamonds$clarity) # Review unique values for clarity
diamonds$clarity <- as.factor(diamonds$clarity) # Factor the clarity to eight levels 
diamonds$clarity <- ordered(diamonds$clarity, levels = c("I1", "SI2", "SI1", "VS2", "VS1", "VVS2", "VVS1", "IF")) # Ordered from worst to best

# table is ok

# price is ok

# Remove values of 0 for for dimensions which includes zeros in length and width
nrow(diamonds[depth %in% 0,]) # Remove 20 rows due to depth = 0.0
diamonds <- diamonds[depth > 0, ] # Include only values with depth greater than zero

# Create formula to check the absolute value of length to width, comparison 
diamonds[, subtraction := abs(length - width)]
nrow(diamonds[subtraction>10,]) # Remove 2 rows due their extreme subtraction value (~59 and ~26)
diamonds <- diamonds[subtraction <= 10, ] # Include only values with subtraction less than ten

diamonds[, depth_check := round(100*(2*depth)/((length + width)), 1)]
diamonds[, diff := abs(depth_check-depth_ratio)]
# treshold at 0.3? anastasia
nrow(diamonds[diff > 0.3,]) # we remove 268 rows
diamonds <- diamonds[diff <= 0.3,]
# hist(diamonds[diff >= 0.4 & diff < 1, diff], breaks = 50)

# Removed created columns needed to clean the data
diamonds[, subtraction := NULL]
diamonds[, depth_check := NULL]
diamonds[, diff := NULL]
# Total rows remove: 275 observations
```


```{r ordering cols}
# Reorder data table to group like variable types 
diamonds <- diamonds[, c(7, 2:4, 1, 8:10, 5:6)]
```

```{r,fig.width = 6, fig.height = 4}
# Used ggpairs to create a scatterplot matrix
# ggpairs(diamonds[, c(1, 5:10)], title = "Scatterplot Matrix",
#          proportions = "auto",
#          columnLabels = c("Price", "Carat", "Length", "Width", "Depth","Depth Ratio","Table"),
#          upper = list(continuous = wrap('cor',size = 3)),) + theme_light()
```

```{r}
ggplot(aes(x = carat, y = price), data = diamonds) + 
  geom_point(alpha = 0.5, size = 1, position = 'jitter',aes(color=clarity)) +
  scale_color_brewer(type = 'div',
                     guide = guide_legend(title = 'Clarity', reverse = T,
                                          override.aes = list(alpha = 1, size = 2))) +                         
  ggtitle('Price by Carat and Clarity')
```



```{r}
diamonds %>% gather() %>% head() # Reshaping the data which means it collects a set of column names and places them into a single “key” column

ggplot(gather(data = diamonds[, c(1, 5:10)]),aes(value)) +
  geom_histogram(aes(y=..density..),bins = 10, color = "white", fill = "blue") + # Creates bin sizing and sets the lines as white
  geom_density(alpha= .2, fill="#56B4E9") +
  facet_wrap(~key,scales = "free") + # Converting the graphs into panels
  ggtitle("Quantitative Variable Analysis") + # Title name
  ylab("Count") + xlab("Value") + # Label names
  theme_classic() # A classic theme, with x and y axis lines and no grid lines
```

```{r}
# Create heatmap to show variable correlation
cormat <- round(cor(diamonds[, c(1, 5:10)]),2) # Round the correlation coefficient to two decimal places

melted_cormat <- melt(cormat) # One way to reshape and elongate the data frame

# Get upper triangle of the correlation matrix
  get_upper_tri <- function(cormat){ 
    cormat[lower.tri(cormat)]<- NA
    return(cormat)
  }

# Rename the correlation coefficient value
upper_tri <- get_upper_tri(cormat)
upper_tri

# Use correlation between variables as distance
reorder_cormat <- function(cormat){ 
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
}

# Reorder the correlation matrix
cormat <- reorder_cormat(cormat)
upper_tri <- get_upper_tri(cormat)

# Melt the correlation matrix
melted_cormat <- melt(upper_tri, na.rm = TRUE)

# Create a ggheatmap with multiple characteristics 
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "purple", high = "blue", mid = "white", midpoint = 0, limit = c(-1,1), space = "Lab", name="Pearson\nCorrelation") +
  ggtitle("Correlation Heatmap") + # Title name
  theme_minimal() + # Minimal theme, keeps in the lines
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
  coord_fixed() +
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 2)

# Print the heat map
print(ggheatmap)
```

```{r}
library(ellipse)
plotcorr(cor(diamonds[, -c(2:4)]))
```

```{r train-valid-test}
# set seed for reproducing the partition
set.seed(111)

# generating training set index
train.index <- sample(c(1:nrow(diamonds)), 0.5*nrow(diamonds))
# generating validation set index taken from the complementary of training set
valid.index <- sample(setdiff(c(1:nrow(diamonds)), train.index), 0.3*nrow(diamonds))
# defining test set index as complementary of (train.index + valid.index)
test.index <- as.numeric(setdiff(row.names(diamonds), union(train.index, valid.index)))
# creating data tables Train, Valid and Test using the indexes
Train <- diamonds[train.index, ]
Valid <- diamonds[valid.index, ]
Test <- diamonds[test.index, ]
```

```{r Data Processing - Trees}
diamonds_tree <- diamonds

Train <- diamonds_tree[train.index, ]
Valid <- diamonds_tree[valid.index, ]
```

```{r Correlation - Price and Continuous Variables}
price_correlation <- with(diamonds,
     data.frame(cor_length_price = cor(length, price),
                cor_width_price = cor(width, price),
                cor_depth_price = cor(depth, price),
                cor_depth_ratio_price = cor(depth_ratio, price),
                cor_table_price2 = cor(table, price),
                cor_carat_price3 = cor(carat, price)
     )
)

kable(price_correlation) %>% kable_classic() 
```


```{r Regression (All) Tree, fig.width = 10, fig.height = 4}
RegressTree <- rpart(price ~ ., 
              data = Train, 
              method = "anova") 

# Generates a cost complexity parameter table that provides the complexity parameter value
summary(RegressTree)

# Count number of leaves 
length(RegressTree$frame$var[RegressTree$frame$var == "<leaf>"]) # 

# Plots a regression tree
fancyRpartPlot(RegressTree, caption = NULL, main = "Regression Tree", palettes = "YlGnBu", digits = -3)
```

```{r}
# kable and kable_styling as before
# we multiply by 100, divide by the sum and round the percentages to 2 decimals.
kable_styling(kable(round(100*RegressTree$variable.importance / sum(RegressTree$variable.importance), 2), col.names = "Importance %"), full_width = FALSE)
```

```{r RegressTree RSME}
RegressTree_pred = predict(RegressTree, newdata= Train)
RMSE_RT = sqrt(mean((Train$price-RegressTree_pred)^2))
RMSE_RT
```

```{r}
RegressTree2 <- rpart(price ~ length+width+depth+carat+cut+color+clarity, 
              data = Train, 
              method = "anova") 

# Generates a cost complexity parameter table that provides the complexity parameter value
summary(RegressTree2)

# Count number of leaves 
length(RegressTree$frame$var[RegressTree2$frame$var == "<leaf>"]) # 

# Plots a regression tree
fancyRpartPlot(RegressTree2, caption = NULL, main = "Exclusion Regression Tree", palettes = "YlGnBu", digits = -3)
```

```{r}
# kable and kable_styling as before
# we multiply by 100, divide by the sum and round the percentages to 2 decimals.
kable_styling(kable(round(100*RegressTree2$variable.importance / sum(RegressTree2$variable.importance), 2), col.names = "Importance %"), full_width = FALSE)
```

```{r RegressTree2 RSME}
p <- predict(RegressTree2, Train)
RMSE <- sqrt(mean((Train$price-p)^2))
RMSE

result = rmse(Train$price, p)
result
result2 = mse(Train$price, p)
result2

R_sq <- (cor(Train$price,p))^2
R_pct <- R_sq*100
R_pct

RegressTree2_pred = predict(RegressTree2, newdata= Train)
RMSE_RT2 = sqrt(mean((Train$price-RegressTree2_pred)^2))
RMSE_RT2

# Calculate MSE
MSE_RT2 <- mean((Train$price-RegressTree2_pred)^2)
MSE_RT2
```

```{r}
accuracy(predict(RegressTree, Train), Train$price)

accuracy(predict(RegressTree, Valid), Valid$price)
```



```{r}
pred_Diamond_test <- predict(RegressTree2, newdata = Valid)
head(pred_Diamond_test,14)
```

```{r}
#Get the lowest CP value from CP table
min.xerror <- RegressTree2$cptable[which.min(RegressTree2$cptable[,"xerror"]),"CP"]

min.xerror
```

```{r}
plotcp(RegressTree2)
```


```{r}
RegressTree_pruned <- prune(RegressTree2, cp = min.xerror) 

# Draw the prune tree
fancyRpartPlot(RegressTree_pruned, caption = NULL, main = "'Pruned' Regression Tree", palettes = "YlGnBu", digits = -3)
```

```{r}
pred_RegressTree_pruned <- predict(RegressTree_pruned, newdata = Train)

fitcorr <- format(cor(Valid$price, pred_RegressTree_pruned)^2, digits=4)

fitcorr
```


# Predictions

```{r Boosted Tree}
# Boosted tree
set.seed(111)
tree_bagged <- boosting(train$price ~., data = Train)
tree_bagged
```


```{r Bagged Tree}
# Boosted tree
set.seed(111)
tree_boosted = boosting(price~.,data = Train[, c(-1)])
tree_boosted
```

```{r Random Forest}
rdf.model <- randomForest(price~ ., ntree= 100, data = Train)
plot(rdf.model)
rdf.model
```

```{r}
# number of trees with lowest MSE
which.min(rdf.model$mse)

# RMSE of this optimal random forest
sqrt(rdf.model$mse[which.min(rdf.model$mse)])
```

```{r}
library(rsample)      # data splitting 
# create training and validation data 

set.seed(111)
diamond_split <- initial_split(diamonds, prop = .6)
diamond_train <- training(diamond_split)
diamons_test  <- testing(diamond_split)

valid_split <- initial_split(diamond_train, .8)

# training data
diamond_train_v2 <- analysis(valid_split)

diamonds_valid <- rsample::assessment(Valid)
x_test <- diamonds_valid[setdiff(names(diamonds_valid), "Price")]
y_test <- diamonds_valid$price

rf_oob_comp <- randomForest(
  formula = price ~ .,
  data    = diamonds_valid,
  xtest   = x_test,
  ytest   = y_test
)

# extract OOB & validation errors
oob <- sqrt(rf_oob_comp$mse)
validation <- sqrt(rf_oob_comp$test$mse)

# compare error rates
tibble::tibble(
  `Out of Bag Error` = oob,
  `Test error` = validation,
  ntrees = 1:rf_oob_comp$ntree
) %>%
  gather(Metric, RMSE, -ntrees) %>%
  ggplot(aes(ntrees, RMSE, color = Metric)) +
  geom_line() +
  scale_y_continuous(labels = scales::dollar) +
  xlab("Number of trees")
```

# Conclusions

# Final Title
