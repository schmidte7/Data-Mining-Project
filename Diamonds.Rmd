---
title: "Diamonds"
author: "Francisco Arrieta, Emily Schmidt and Lucia Camenisch"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true             # creating a table of contents (toc)
    toc_float: 
      collapsed: false    # toc does not collapse and is shown as a sidebar (toc_float)
    number_sections: true # document sections are numbered
    theme: cosmo
---

```{=html}
<style>
body{
  color: #2F91AE;
  background-color: #F2F2F2;
}
pre{
  background-color: #96EAE3;
}
pre:not([class]){
  background-color: #15DDD8;
}
.toc-content{
  padding-left: 10px;
  padding-right: 10px;
}
.col-sm-8 {
  width: 75%;
}
code {
  color: #333333;
  background-color: #96EAE3;
}
</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.align = "center")
```

```{r Colors, include=FALSE}
#Aqua =         "#15DDD8"
#Dark Blue =    "#2F91AE"
#Yellow =       "#F9D53E"
#Light Gray =   "#F2F2F2"
#Light Aqua =   "#96EAE3"
```

```{r Libraries}
library(data.table)     #for reading data.tables
library(ggplot2)        #for making graphs
library(tidyr)          #for changing the shape and hierarchy of a data set
library(ellipse)        #for mapping correlation
library(e1071)          #for skewness
library(caret)          #for preProcess() and accuracy()
library(fastDummies)    #for creating dummies
# library(kableExtra)     #for more elaborate tables
# library(GGally)         #for making graphs
# library(dplyr)          #for data manipulation
# library(DataExplorer)   #for graphing missing value percentages
# library(car)            #for statistic functions


source("VIF.R")
source("ProcStep.R")
source("GlobalCrit.R")
options(scipen = 999)
```

# Data Exploration 

```{r Import Data}
diamonds <- fread("diamonds.csv") # Load your data, diamonds.csv

diamonds$V1 <- NULL # Remove column 'V1' as it is similar to an ID variable - no additional meaning derived

# Rename columns for more precise names
colnames(diamonds)[5] <- "depth_ratio" # depth to depth_ratio
colnames(diamonds)[8] <- "length" # x to length
colnames(diamonds)[9] <- "width"  # y to width
colnames(diamonds)[10] <- "depth" # z to depth
```


```{r categorical-as-factors}
# Review unique values for cut
unique(diamonds$cut)
# Factor the cut to five levels
diamonds$cut <- as.factor(diamonds$cut)
# Ordered from worst to best
diamonds$cut <- ordered(diamonds$cut, levels = c("Fair", "Good", "Very Good", "Premium", "Ideal"))

# Review unique values for color
unique(diamonds$color)
# Factor the color to seven levels 
diamonds$color <- as.factor(diamonds$color) 
# Ordered from worst to best
diamonds$color <- ordered(diamonds$color, levels = c("J", "I", "H", "G", "F", "E", "D"))

# Review unique values for clarity
unique(diamonds$clarity)
# Factor the clarity to eight levels 
diamonds$clarity <- as.factor(diamonds$clarity)
# Ordered from worst to best
diamonds$clarity <- ordered(diamonds$clarity,
                            levels = c("I1", "SI2", "SI1", "VS2", "VS1", "VVS2", "VVS1", "IF"))
```


```{r removing-rows}
# Remove values of 0 for for dimensions which includes zeros in length and width
nrow(diamonds[depth %in% 0,])        # Remove 20 rows due to depth = 0.0
diamonds <- diamonds[depth > 0, ]    # Include only values with depth greater than zero

# Create formula to check the absolute value of length to width, comparison 
diamonds[, subtraction := abs(length - width)]
# Remove 2 rows due their extreme subtraction value (~59 and ~26)
nrow(diamonds[subtraction>10,])
# Include only values with subtraction less than ten
diamonds <- diamonds[subtraction <= 10, ]

diamonds[, depth_check := round(100*(2*depth)/((length + width)), 1)]
diamonds[, diff := abs(depth_check-depth_ratio)]
# treshold at 0.3? anastasia
nrow(diamonds[diff > 0.3,]) # we remove 253 rows
diamonds <- diamonds[diff <= 0.3,]
# hist(diamonds[diff >= 0.4 & diff < 1, diff], breaks = 50)

# Removed created columns needed to clean the data
diamonds[, subtraction := NULL]
diamonds[, depth_check := NULL]
diamonds[, diff := NULL]
# Total rows removed: 275 observations
```


```{r ordering cols}
# Reorder data table to group like variable types 
diamonds <- diamonds[, c(7, 2:4, 1, 8:10, 5:6)]
```



```{r Histograms}
ggplot(gather(data = diamonds[, c(1, 5:10)]), aes(value)) +
  geom_histogram(aes(y = after_stat(density)),
#                 bins = 10,
                 color = "white",
                 fill = "#F9D53E") + # Creates bin sizing with colors
  geom_density(alpha = .2, fill = "#F9D53E") +
  facet_wrap(~ key, scales = "free") + # Converting the graphs into panels
  ggtitle("Quantitative Variable Analysis") + # Title name
  ylab("Count") + xlab("Value") + # Label names
  theme_classic() # A classic theme, with x and y axis lines and no grid lines
```

```{r Correlation}
# Create heatmap to show variable correlation
# Round the correlation coefficient to two decimal places
cormat <- round(cor(diamonds[, c(1, 5:10)]), 2)

# Use correlation between variables as distance
reorder_cormat <- function(cormat){ 
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
return(cormat)
}

# Reorder the correlation matrix
cormat <- reorder_cormat(cormat)

# Keeping only upper triangular matrix
# upper_tri returns TRUE/FALSE for each coordinate (TRUE -> part of upper triangle)
# multiplying will thus keep the upper triangle values and set the others to 0
cormat <- cormat*upper.tri(cormat, diag = TRUE)
# Values of the lower triangle (0) are replaced by NA
cormat[cormat == 0] <- NA

# Melt the correlation matrix
cormat <- reshape2::melt(cormat, na.rm = TRUE)

# Create a ggheatmap with multiple characteristics 
ggplot(cormat, aes(Var2, Var1, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "#15DDD8", high = "#F9D53E", mid = "white",
                       midpoint = 0, limit = c(-1,1), space = "Lab", name="Pearson\nCorrelation") +
  ggtitle("Correlation Heatmap") + # Title name
  theme_minimal() + # Minimal theme, keeps in the lines
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
  coord_fixed() +
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 2)

rm(cormat, reorder_cormat)
```

```{r Correlation Plot}
plotcorr(cor(diamonds[, -c(2:4)]), col = "#F9D53E",
         main = "Pearson correlation ellipses for numerical variables")
```

```{r train-valid-test}
# set seed for reproducing the partition
set.seed(111)

# generating training set index
train.index <- sample(c(1:nrow(diamonds)), 0.5*nrow(diamonds))
# generating validation set index taken from the complementary of training set
valid.index <- sample(setdiff(c(1:nrow(diamonds)), train.index), 0.3*nrow(diamonds))
# defining test set index as complementary of (train.index + valid.index)
test.index <- as.integer(setdiff(row.names(diamonds), union(train.index, valid.index)))
```


## Linear Regression


```{r train-valid-test}
Train <- diamonds[train.index, ]
Valid <- diamonds[valid.index, ]
Test  <- diamonds[ test.index, ]
```


```{r vif}
VIF(y = diamonds$price, matx = diamonds[, -c(1)])
VIF(y = diamonds$price, matx = diamonds[, -c(1, 6, 7, 8)])

plotcorr(cor(diamonds[, -c(2:4, 6:8)]), col = "#F9D53E",
         main = "Pearson correlation ellipses for numerical variables")
```

```{r skewness}
sapply(Train[, c(1, 5:10)], skewness)
Train$price <- log(Train$price)
Train$carat <- log(Train$carat)
Train$table <- log(Train$table)
sapply(Train[, c(1, 5:10)], skewness)
```

```{r hist-unskewed}
ggplot(gather(data = Train[, c(1, 5:10)]), aes(value)) +
  geom_histogram(aes(y = after_stat(density)),
                 color = "white",
                 fill = "#F9D53E") +             # Creates bin sizing with colors
  geom_density(alpha = .2, fill = "#F9D53E") +
  facet_wrap(~ key, scales = "free") +           # Converting the graphs into panels
  ggtitle("Histograms of numerical variables") + # Title name
  ylab("Count") + xlab("Value") +                # Label names
  theme_classic()                                # Theme with x and y axis lines and no grid lines
```

```{r normalizing}
norm.values <- preProcess(Train[, c(1, 5:10)], method=c("center", "scale"))

Train[, c(1, 5:10)] <- predict(norm.values, Train[, c(1, 5:10)])
Valid[, c(1, 5:10)] <- predict(norm.values, Valid[, c(1, 5:10)])
 Test[, c(1, 5:10)] <- predict(norm.values,  Test[, c(1, 5:10)])
```

```{r LM-complete}
LM_complete = lm(price ~. , data = Train)
summary(LM_complete)
```


```{r LM-minus-corr}
Train_minus_corr <- Train[, -c(6:8)]
LM_minus_corr = lm(price ~ ., data = Train_minus_corr)
summary(LM_minus_corr)
```


```{r iterative-search-complete}
LM_backward = step(LM_complete, direction = "backward")
summary(LM_backward)   # like LM_CpAIC_complete
LM_forward = step(LM_complete, direction = "forward")
summary(LM_forward)    # no selection
LM_stepwise = step(LM_complete, direction = "both")
summary(LM_stepwise)   # like LM_CpAIC_complete
```


```{r iterative-search-minus-corr}
LM_backward_minus_corr = step(LM_minus_corr, direction = "backward")
summary(LM_backward_minus_corr)   # like LM_CpAIC_minus_corr
LM_forward_minus_corr = step(LM_minus_corr, direction = "forward")
summary(LM_forward_minus_corr)    # no selection
LM_stepwise_minus_corr = step(LM_minus_corr, direction = "both")
summary(LM_stepwise_minus_corr)   # like LM_CpAIC_minus_corr
```


```{r global-methods}
GlobalCrit(LM_complete)
GlobalCrit(LM_minus_corr)

LM_CpAIC_complete = lm(price ~ . , data = Train[, c(1:6, 8, 9)])
summary(LM_CpAIC_complete)
LM_CpAIC_minus_corr = lm(price ~ . , data = Train[, c(1:5, 9)])
summary(LM_CpAIC_minus_corr)
```


with all variables:
  cut              
  color            
  clarity          
  carat            
  length           
  depth            
  depth_ratio
  
taking out the correlated ones:
  cut              
  color            
  clarity          
  carat            
  depth_ratio  



```{r dummies-and-dummies-minus-corr}
TrainD = dummy_cols(Train,
                    select_columns = c("cut", "color", "clarity"),
                    remove_first_dummy = TRUE,
                    remove_selected_columns = TRUE)

TrainD_minus_corr <- TrainD[, -c(3:5)]

LM_dummies <- lm(price ~ . , data = TrainD)
summary(LM_dummies)

LM_dummies_minus_corr <- lm(price ~ . , data = TrainD_minus_corr)
summary(LM_dummies_minus_corr)
```


```{r iterative-search-dummies}
LM_backward_dummies = step(LM_dummies, direction = "backward")
summary(LM_backward_dummies)   # missing width and table
LM_forward_dummies = step(LM_dummies, direction = "forward")
summary(LM_forward_dummies)    # no selection
LM_stepwise_dummies = step(LM_dummies, direction = "both")
summary(LM_stepwise_dummies)   # missing width and table
```


```{r iterative-search-dummies-minus-corr}
LM_backward_dummies_minus_corr = step(LM_dummies_minus_corr, direction = "backward")
summary(LM_backward_dummies_minus_corr)   # missing table
LM_forward_dummies_minus_corr = step(LM_dummies_minus_corr, direction = "forward")
summary(LM_forward_dummies_minus_corr)    # no selection
LM_stepwise_dummies_minus_corr = step(LM_dummies_minus_corr, direction = "both")
summary(LM_stepwise_dummies_minus_corr)   # missing table
```


```{r}
# GlobalCrit(LM_backward_dummies)
# GlobalCrit(LM_backward_dummies_minus_corr)
```

```{r}

```

